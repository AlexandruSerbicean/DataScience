{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Python Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crist\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/dhruvildave/new-york-city-taxi-trips-2019?dataset_version_number=4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2.38G/2.38G [01:11<00:00, 35.7MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"dhruvildave/new-york-city-taxi-trips-2019\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in dataset: ['2019', 'data_dictionary.pdf', 'taxi_zones', 'taxi_zone_lookup.csv']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "files = os.listdir(path)\n",
    "print(\"Files in dataset:\", files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in 2019 folder: ['2019-01.sqlite', '2019-02.sqlite', '2019-03.sqlite', '2019-04.sqlite', '2019-05.sqlite', '2019-06.sqlite', '2019-07.sqlite', '2019-08.sqlite', '2019-09.sqlite', '2019-10.sqlite', '2019-11.sqlite', '2019-12.sqlite']\n",
      "Files in taxi_zones folder: ['taxi_zones.dbf', 'taxi_zones.prj', 'taxi_zones.sbn', 'taxi_zones.sbx', 'taxi_zones.shp', 'taxi_zones.shp.xml', 'taxi_zones.shx']\n"
     ]
    }
   ],
   "source": [
    "dataset_path = path\n",
    "\n",
    "year_2019_path = os.path.join(dataset_path, \"2019\")\n",
    "if os.path.exists(year_2019_path):\n",
    "    print(\"Files in 2019 folder:\", os.listdir(year_2019_path))\n",
    "\n",
    "taxi_zones_path = os.path.join(dataset_path, \"taxi_zones\")\n",
    "if os.path.exists(taxi_zones_path):\n",
    "    print(\"Files in taxi_zones folder:\", os.listdir(taxi_zones_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-01.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-01.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-02.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-02.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-03.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-03.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-04.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-04.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-05.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-05.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-06.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-06.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-07.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-07.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-08.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-08.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-09.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-09.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-10.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-10.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-11.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-11.sqlite\n",
      "Processing C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-12.sqlite...\n",
      "Finished C:\\Users\\crist\\.cache\\kagglehub\\datasets\\dhruvildave\\new-york-city-taxi-trips-2019\\versions\\4\\2019\\2019-12.sqlite\n",
      "All data saved to CSV without crashing!\n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "output_csv = \"nyc_taxi_2019_combined.csv\"\n",
    "\n",
    "sqlite_files = [os.path.join(path, \"2019\", f) for f in os.listdir(os.path.join(path, \"2019\")) if f.endswith(\".sqlite\")]\n",
    "\n",
    "first_file = sqlite_files[0]\n",
    "conn = sqlite3.connect(first_file)\n",
    "df_temp = pd.read_sql(\"SELECT * FROM tripdata LIMIT 1000;\", conn) \n",
    "conn.close()\n",
    "df_temp.to_csv(output_csv, index=False)  \n",
    "\n",
    "for file in sqlite_files:\n",
    "    print(f\"Processing {file}...\")\n",
    "    conn = sqlite3.connect(file)\n",
    "\n",
    "    chunk_size = 500000 \n",
    "    for chunk in pd.read_sql(\"SELECT * FROM tripdata;\", conn, chunksize=chunk_size):\n",
    "        chunk.to_csv(output_csv, mode='a', header=False, index=False)\n",
    "\n",
    "    conn.close()\n",
    "    print(f\"Finished {file}\")\n",
    "\n",
    "print(\"All data saved to CSV without crashing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 9923 entries, 0 to 9999\n",
      "Data columns (total 18 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   vendorid               9923 non-null   float64       \n",
      " 1   tpep_pickup_datetime   9923 non-null   datetime64[ns]\n",
      " 2   tpep_dropoff_datetime  9923 non-null   datetime64[ns]\n",
      " 3   passenger_count        9923 non-null   float64       \n",
      " 4   trip_distance          9923 non-null   float64       \n",
      " 5   ratecodeid             9923 non-null   float64       \n",
      " 6   store_and_fwd_flag     9923 non-null   object        \n",
      " 7   pulocationid           9923 non-null   float64       \n",
      " 8   dolocationid           9923 non-null   float64       \n",
      " 9   payment_type           9923 non-null   float64       \n",
      " 10  fare_amount            9923 non-null   float64       \n",
      " 11  extra                  9923 non-null   float64       \n",
      " 12  mta_tax                9923 non-null   float64       \n",
      " 13  tip_amount             9923 non-null   float64       \n",
      " 14  tolls_amount           9923 non-null   float64       \n",
      " 15  improvement_surcharge  9923 non-null   float64       \n",
      " 16  total_amount           9923 non-null   float64       \n",
      " 17  congestion_surcharge   0 non-null      float64       \n",
      "dtypes: datetime64[ns](2), float64(15), object(1)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "   vendorid tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       1.0  2019-01-01 00:46:40   2019-01-01 00:53:20              1.0   \n",
      "1       1.0  2019-01-01 00:59:47   2019-01-01 01:18:59              1.0   \n",
      "7       1.0  2019-01-01 00:21:28   2019-01-01 00:28:37              1.0   \n",
      "8       1.0  2019-01-01 00:32:01   2019-01-01 00:45:39              1.0   \n",
      "9       1.0  2019-01-01 00:57:32   2019-01-01 01:09:32              2.0   \n",
      "\n",
      "   trip_distance  ratecodeid store_and_fwd_flag  pulocationid  dolocationid  \\\n",
      "0            1.5         1.0                  N         151.0         239.0   \n",
      "1            2.6         1.0                  N         239.0         246.0   \n",
      "7            1.3         1.0                  N         163.0         229.0   \n",
      "8            3.7         1.0                  N         229.0           7.0   \n",
      "9            2.1         1.0                  N         141.0         234.0   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0           1.0          7.0    0.5      0.5        1.65           0.0   \n",
      "1           1.0         14.0    0.5      0.5        1.00           0.0   \n",
      "7           1.0          6.5    0.5      0.5        1.25           0.0   \n",
      "8           1.0         13.5    0.5      0.5        3.70           0.0   \n",
      "9           1.0         10.0    0.5      0.5        1.70           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3          9.95                   NaN  \n",
      "1                    0.3         16.30                   NaN  \n",
      "7                    0.3          9.05                   NaN  \n",
      "8                    0.3         18.50                   NaN  \n",
      "9                    0.3         13.00                   NaN  \n",
      "   vendorid tpep_pickup_datetime tpep_dropoff_datetime  passenger_count  \\\n",
      "0       1.0  2019-01-01 00:46:40   2019-01-01 00:53:20              1.0   \n",
      "1       1.0  2019-01-01 00:59:47   2019-01-01 01:18:59              1.0   \n",
      "7       1.0  2019-01-01 00:21:28   2019-01-01 00:28:37              1.0   \n",
      "8       1.0  2019-01-01 00:32:01   2019-01-01 00:45:39              1.0   \n",
      "9       1.0  2019-01-01 00:57:32   2019-01-01 01:09:32              2.0   \n",
      "\n",
      "   trip_distance  ratecodeid store_and_fwd_flag  pulocationid  dolocationid  \\\n",
      "0            1.5         1.0                  N         151.0         239.0   \n",
      "1            2.6         1.0                  N         239.0         246.0   \n",
      "7            1.3         1.0                  N         163.0         229.0   \n",
      "8            3.7         1.0                  N         229.0           7.0   \n",
      "9            2.1         1.0                  N         141.0         234.0   \n",
      "\n",
      "   payment_type  fare_amount  extra  mta_tax  tip_amount  tolls_amount  \\\n",
      "0           1.0          7.0    0.5      0.5        1.65           0.0   \n",
      "1           1.0         14.0    0.5      0.5        1.00           0.0   \n",
      "7           1.0          6.5    0.5      0.5        1.25           0.0   \n",
      "8           1.0         13.5    0.5      0.5        3.70           0.0   \n",
      "9           1.0         10.0    0.5      0.5        1.70           0.0   \n",
      "\n",
      "   improvement_surcharge  total_amount  congestion_surcharge  \n",
      "0                    0.3          9.95                   NaN  \n",
      "1                    0.3         16.30                   NaN  \n",
      "7                    0.3          9.05                   NaN  \n",
      "8                    0.3         18.50                   NaN  \n",
      "9                    0.3         13.00                   NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"nyc_taxi_2019_combined.csv\", nrows=10000, low_memory=False)\n",
    "\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "df = df[(df['trip_distance'] > 0) & (df['fare_amount'] > 0)]\n",
    "\n",
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Cleaning Complete!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[['trip_distance', 'fare_amount', 'total_amount', 'tolls_amount']] = scaler.fit_transform(df[['trip_distance', 'fare_amount', 'total_amount', 'tolls_amount']])\n",
    "\n",
    "df['payment_type'] = df['payment_type'].astype(int)\n",
    "df['vendorid'] = df['vendorid'].astype(int)\n",
    "df['ratecodeid'] = df['ratecodeid'].astype(int)\n",
    "\n",
    "Q1 = df[['fare_amount', 'trip_distance']].quantile(0.25)\n",
    "Q3 = df[['fare_amount', 'trip_distance']].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df = df[~((df[['fare_amount', 'trip_distance']] < (Q1 - 1.5 * IQR)) | (df[['fare_amount', 'trip_distance']] > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "\n",
    "print(\"Data Cleaning Complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
